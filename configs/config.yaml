bot:
  token: "8479463724:AAHzlbx-9qMUarK5BMG9hAnbAzvCQT1IJ9g"
  debug: false
  webhook:
    enabled: false
    url: ""
    port: 8443

database:
  driver: "sqlite3"
  dsn: "./data/mmemory.db"
  max_open_conns: 25
  max_idle_conns: 10

server:
  port: 8080
  host: "0.0.0.0"
  
scheduler:
  timezone: "Asia/Shanghai"
  max_workers: 10
  
logging:
  level: "info"  # debug, info, warn, error
  format: "json"  # json, text
  output: "stdout"  # stdout, file
  file_path: "./data/mmemory.log"
  
app:
  name: "MMemory"
  version: "v0.0.1"
  environment: "development"  # development, production

# 监控配置
monitoring:
  # 是否启用监控 - 可选，默认 true
  enabled: true

  # 监控端口 - 可选，默认 9090
  port: 9090

  # 监控路径 - 可选，默认 "/metrics"
  path: "/metrics"

# AI配置
ai:
  # 是否启用AI功能 - 从环境变量 MMEMORY_AI_ENABLED 读取
  enabled: false

  # OpenAI配置
  openai:
    # API Key - 从环境变量 MMEMORY_AI_OPENAI_API_KEY 读取
    api_key: ""

    # API Base URL - 从环境变量 MMEMORY_AI_OPENAI_BASE_URL 读取
    base_url: "https://api.openai.com/v1"

    # 主要模型 - 从环境变量 MMEMORY_AI_OPENAI_PRIMARY_MODEL 读取
    primary_model: "gpt-4o-mini"

    # 备用模型 - 从环境变量 MMEMORY_AI_OPENAI_BACKUP_MODEL 读取
    backup_model: "gpt-3.5-turbo"

    # Temperature参数
    temperature: 0.1

    # 最大Token数
    max_tokens: 1000

    # 请求超时
    timeout: "30s"

    # 最大重试次数
    max_retries: 3

  # Prompt模板配置（使用默认值）
  prompts:
    reminder_parse: ""
    chat_response: ""